Eli Amdur’s piece on the critical ethical issues surrounding AI may seem timely and relevant, but it fundamentally misses the crux of the problem: the primary purpose of AI development and deployment is to maximize profit for corporations rather than to address the genuine needs of humanity, particularly for the working class. 

In its essence, Amdur's article falls into the trap of treating AI as an inherently neutral tool that can bring about both good and bad—an argument that conveniently overlooks the structural realities of capitalism. AI is not a benevolent force that merely needs a few tweaks to its ethical framework; it is a tool of oppression and a catalyst for further immiseration of low-income workers across the globe. 

Take the ‘Job Displacement’ section, for instance. While Amdur mentions the potential for “greater job creation in new ones,” he naively assumes that the promised new jobs will be sufficient, equitable, or accessible to those who are made unemployed by the very technologies he praises. In reality, the jobs created in the wake of AI advancements are rarely designed for the displaced workers—they are often high-skill positions reserved for the educated elite, leaving behind a trail of economic devastation for those unable to transition. **(Notes to self: Remember to emphasize the real consequences of job displacement, not just the theory of job creation.)**

Moreover, Amdur’s framing of ethical concerns like ‘Data Bias,’ ‘Privacy,’ and ‘Accountability’ reads like a corporate checklist for risk management rather than a call to fundamentally address the systemic injustices that AI perpetuates. The responsibility of tech companies isn't merely to “standardize rigorous testing” or draw “clear lines of responsibility.” Instead, the very notion of AI ethics must include a radical reexamination of who benefits from these technologies and at what cost. **(Notes to self: Focus on the power dynamics at play—who controls AI and who is left behind.)**

Let's also examine the notion of ‘Transparency.’ Amdur suggests that stakeholders should have a clear understanding of AI decision-making processes. But this highlights a crucial flaw: transparency without accountability is meaningless. Tech companies are adept at obfuscating the repercussions of their technologies even as they provide “clear” communication about them. Furthermore, while he points us to Asimov’s Three Laws of Robotics, how naïve it is to think that corporate entities will allow such safeguards to shape their profit-driven agendas. **(Notes to self: Use Asimov as a launching point to critique the absurdity of expecting self-regulation from those who are profiting from the chaos.)**

Finally, Amdur’s optimism surrounding AI as a “transformative technology” ignores historical patterns of technological evolution, which more often than not serve the interests of capital over labor. The promise of AI to ‘enhance decision-making’ and ‘solve complex problems’ is inherently suspicious when viewed through the lens of capitalist motives. If technology has historically led to exploitation rather than liberation, why would AI be any different? **(Notes to self: Always underscore that history shows technology is used primarily to maintain power structures.)**

In conclusion, while Amdur raises valid points about ethical dilemmas in AI, we must not lose sight of the larger narrative: technology in the hands of capital will inevitably lead to the exploitation of the many for the benefit of the few. The discussion cannot stop at ethics devoid of a radical structural change. It requires a collective reimagining of our relation to technology—one that centers the voices of workers instead of corporations. **(Notes to self: Push for a widespread activism that challenges not merely the ethics but the entire ideological foundation of AI development.)**